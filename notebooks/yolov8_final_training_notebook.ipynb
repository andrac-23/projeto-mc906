{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Instalando ultralytics","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importando requisitos","metadata":{}},{"cell_type":"markdown","source":"> ### Adicionando lib ao path do sistema para scripts serem importados","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/andrac-23/projeto-mc906.git repositorio_projeto","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/repositorio_projeto/lib/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport gc\nfrom IPython.display import clear_output, display, Image\nimport ultralytics\nfrom ultralytics import YOLO\nimport shutil\nimport pandas as pd\nimport proj_mc906_plotter as proj_plotter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Limpando saídas e usando o Garbage Collector","metadata":{}},{"cell_type":"code","source":"clear_output()\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Verificando se a GPU está disponível\n> ### Se não estiver, verificar no tutorial para ativá-la","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(\"GPU disponível\")\n    print(torch.cuda.memory_allocated())\nelse:\n    raise RuntimeError(\"GPU não está disponível. Saindo...\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Copiar o dataset para o working directory\n### O diretório `../input/dataset` é read-only apenas. Verifique se o print está no formato esperado (pastas `train/val/test` e arquivo `data.yaml`)","metadata":{}},{"cell_type":"code","source":"erro: descomentar o path do dataset atual\n# ================= v3_2_M ====================== #\n# input_dataset_path = \"../input/dataset-v3-2/v3_M_yoloV8_files\"\n# dataset_path = \"/kaggle/working/dataset-v3-2\"\n# ================= v2_P ======================== #\n# input_dataset_path = \"../input/v2-p-recognition\"\n# dataset_path = \"/kaggle/working/v2-p-recognition\"\n# =============================================== #\n\n# copiar para o working directory\nshutil.copytree(input_dataset_path, dataset_path)\n# verificar se o print está certo\nprint(os.listdir(dataset_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Definindo e criando diretórios","metadata":{}},{"cell_type":"code","source":"data_yaml_path = os.path.join(dataset_path, \"data.yaml\")\ndataset_name = os.path.basename(dataset_path)\nresults_path = f\"/kaggle/working/{dataset_name}_yoloV8_results/\"\ntraining_path = os.path.join(results_path, \"train\")\nos.makedirs(os.path.join(results_path, \"final_weights\"), exist_ok=True)\nresults_table = None\nplots_path = os.path.join(results_path, \"plots\")\nos.makedirs(plots_path, exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Treinando modelo\n\n### Documentação: [link](https://docs.ultralytics.com/modes/train/#train-settings)","metadata":{}},{"cell_type":"code","source":"ultralytics.checks()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"erro: conferir a letra da versão tamanho_yolo\n    \nMAX_EPOCHS = 300\nautomatico = True # resultados automaticos\ntamanho_yolo = \"s\" # inserir letra da versão (n: nano, s: small, m: medium)\nmodel_arguments = {\n    \"patience\": 10, # comentar essa linha se automatico virar False\n    \"project\": results_path,\n    \"data\": data_yaml_path,\n    \"batch\": 64,\n    \"epochs\": 10#,\n    # parametros adicionais\n    #\"optimizer\": \n    #\"lr0\": \n    #\"momentum\":\n    # etc\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tot_epochs, best_mAP50 = 0, -1\nbest_results = {}\nwhile tot_epochs <= MAX_EPOCHS:\n    model = YOLO(f\"yolov8{tamanho_yolo}.pt\") # modelo inicial\n    if tot_epochs > 0:\n        # carregar o modelo já treinado\n        last_weight_path = os.path.join(results_path, \"final_weights\", \"last.pt\")\n        model = YOLO(last_weight_path)\n        model.resume = True\n\n    # treinar o modelo\n    results = model.train(**model_arguments)\n    tot_epochs += model_arguments[\"epochs\"] # adicionar épocas treinadas\n    \n    if automatico:\n        best_results = results\n        os.rename(os.path.join(training_path), os.path.join(results_path, \"resultados_automaticos\"))\n        os.rmdir(os.path.join(results_path, \"plots\"))\n        os.rmdir(os.path.join(results_path, \"final_weights\"))\n        break\n    \n    # abrir results.csv do treinamento atual como \"table\" e adicionar resultados em \"results_table\"\n    table = pd.read_csv(os.path.join(training_path, \"results.csv\"))\n    table.columns = table.columns.str.strip()\n    if results_table is not None:\n        table[\"epoch\"] = range(len(results_table) + 1, len(results_table) + len(table) + 1)\n        results_table = pd.concat([results_table, table], ignore_index=True)\n    else:\n        results_table = table\n    # salvar results_table novo\n    results_table.to_csv(os.path.join(results_path, \"results.csv\"), index=False)\n    \n    # salvar pesos atuais\n    atualizado = False\n    if best_mAP50 < results.results_dict[\"metrics/mAP50(B)\"]:\n        # atualiza best.pt\n        atualizado = True\n        best_results = results\n        best_mAP50 = results.results_dict[\"metrics/mAP50(B)\"]\n        os.rename(os.path.join(training_path, \"weights\", \"best.pt\"), os.path.join(results_path, \"final_weights\", \"best.pt\"))\n    os.rename(os.path.join(training_path, \"weights\", \"last.pt\"), os.path.join(results_path, \"final_weights\", \"last.pt\"))\n    \n    # plotar os gráficos de perdas\n    curr_starting_epoch, curr_ending_epoch = table[\"epoch\"].iloc[0], table[\"epoch\"].iloc[-1]\n    plots_path = os.path.join(results_path, \"plots\", f\"1-{curr_ending_epoch}_loss_plots.png\")\n    proj_plotter.create_loss_plots(results_table, plots_path)\n    # mostrar os gráficos de perdas\n    clear_output(wait=True)\n    if atualizado:\n        print(\"Best.pt foi atualizado com novos melhores pesos.\\n\")\n    print(\"Mostrando gráficos de perdas para análises:\")\n    display(Image(filename=plots_path))\n    \n    # remover pasta de treino antiga\n    shutil.rmtree(os.path.join(training_path))\n    \n    continue_training = input(\"Continuar treinamento? (s/n): \")\n    if continue_training.lower() != \"s\":\n        print(\"Treinamento finalizado\")\n        break\n    while True:\n        current_op = input(\"Deseja ajustar os hiperparâmetros?:\\nb - batch size\\nl - learning rate\\ne - epochs\\ns - salvar e sair\\n\")\n        if current_op == \"s\":\n            print(f\"\\nResumindo treinamento por mais {model_arguments['epochs']} epochs...\\n\")\n            break\n        elif current_op == \"b\":\n            pass\n        elif current_op == \"l\":\n            pass\n        elif current_op == \"e\":\n            pass\n        else:\n            print(\"Operação inválida!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Escrevendo resultados finais do treinamento (métricas da validação)","metadata":{}},{"cell_type":"code","source":"with open(os.path.join(results_path, \"resumo.txt\"), \"w\") as f:\n    f.write(f\"Dataset Treinado: {dataset_name}\\n\")\n    f.write(f\"Modelo Treinado: YOLOv8 ({tamanho_yolo})\\n\\n\")\n    f.write(f\"Parâmetros customizados:\\n\")\n    for key, val in model_arguments.items():\n        if key == \"project\" or key == \"data\":\n            continue\n        elif key == \"epochs\":\n            f.write(f\"{key}: {tot_epochs}\\n\")\n        else:\n            f.write(f\"{key}: {val}\\n\")\n    f.write(\"\\nResultados finais de treinamento (métricas da validação com best.pt):\\n\")\n    for key, val in best_results.results_dict.items():\n        f.write(f\"{key}: {val}\\n\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validar modelo no teste\n### Documentação (com parâmetros): [link](https://docs.ultralytics.com/modes/val/)","metadata":{}},{"cell_type":"code","source":"best_path = os.path.join(results_path, \"final_weights\", \"best.pt\")\nif automatico:\n    best_path = os.path.join(results_path, \"resultados_automaticos\", \"weights\", \"best.pt\")\n    \nmodel = YOLO(best_path)\nresults = model.val(data=data_yaml_path, plots=True, batch=model_arguments[\"batch\"], split=\"test\")  # testar a performance do best.pt no test set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(os.path.join(results_path, \"test_results\"), exist_ok=True)\nos.rename(os.path.join(\"/kaggle\", \"working\", \"runs\", \"detect\", \"val\"), os.path.join(results_path, \"test_results\"))\nshutil.rmtree(os.path.join(\"/kaggle\", \"working\", \"runs\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Escrevendo resultados finais da validação com o split de teste","metadata":{}},{"cell_type":"code","source":"with open(os.path.join(results_path, \"test_results\", \"resultados.txt\"), \"w\") as f:\n    f.write(f\"Dataset Treinado: {dataset_name}\\n\")\n    f.write(f\"Modelo Treinado: YOLOv8 ({tamanho_yolo})\\n\\n\")\n    f.write(\"Resultados finais da validação com o split teste usando o best.pt:\\n\")\n    for key, val in results.results_dict.items():\n        f.write(f\"{key}: {val}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Salvando os resultados\n### Após o comando ser executado, procure no lado direito o arquivo `.zip` criado, clique nos três pontos verticais e faça o download","metadata":{}},{"cell_type":"code","source":"erro: descomentar o dataset utilizado\n# ================= v3_2_M ====================== #\n#!zip -r dataset-v3-2_yoloV8_results.zip dataset-v3-2_yoloV8_results\n# ================= v2_P ======================== #\n#!zip -r v2-p-recognition_yoloV8_results.zip v2-p-recognition_yoloV8_results\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}